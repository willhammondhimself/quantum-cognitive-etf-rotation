{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# Walk-Forward Diagnostic Analysis\n",
    "\n",
    "This notebook investigates why our models fail in walk-forward validation:\n",
    "- **Single-split Sharpe**: +0.301\n",
    "- **Walk-forward Sharpe**: -0.969\n",
    "\n",
    "Goals:\n",
    "1. Identify when/where models fail (time periods, regimes)\n",
    "2. Analyze prediction quality (rank correlation, hit rate trends)\n",
    "3. Understand feature effectiveness\n",
    "4. Guide feature engineering efforts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "import json\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from scipy import stats\n",
    "\n",
    "from qcml_rotation.analysis.diagnostics import (\n",
    "    analyze_time_periods,\n",
    "    analyze_prediction_quality,\n",
    "    compute_rank_correlation,\n",
    "    analyze_regime_performance,\n",
    "    compute_rolling_metrics,\n",
    "    compute_train_test_gap,\n",
    "    create_diagnostic_report\n",
    ")\n",
    "from qcml_rotation.backtest.metrics import (\n",
    "    bootstrap_sharpe_ci,\n",
    "    sharpe_p_value,\n",
    "    permutation_test,\n",
    "    compute_significance\n",
    ")\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette('husl')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "plt.rcParams['font.size'] = 11\n",
    "\n",
    "print(\"Diagnostic analysis ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-2",
   "metadata": {},
   "source": [
    "## 1. Load Data and Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load processed data\n",
    "with open('../data/processed/processed_data.pkl', 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "splits = data['splits']\n",
    "feature_cols = data['feature_cols']\n",
    "prices = data['prices']\n",
    "rebalance_dates = data['rebalance_dates']\n",
    "\n",
    "print(f\"Feature columns: {feature_cols}\")\n",
    "print(f\"Total weeks: {len(rebalance_dates)}\")\n",
    "print(f\"Date range: {rebalance_dates[0]} to {rebalance_dates[-1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load walk-forward results if available\n",
    "wf_path = Path('../outputs/walk_forward/walk_forward_results.json')\n",
    "\n",
    "if wf_path.exists():\n",
    "    with open(wf_path, 'r') as f:\n",
    "        wf_results = json.load(f)\n",
    "    print(\"Loaded walk-forward results\")\n",
    "    print(f\"Models: {list(wf_results['models'].keys())}\")\n",
    "else:\n",
    "    print(\"Walk-forward results not found. Run the script first:\")\n",
    "    print(\"  python scripts/run_walk_forward.py\")\n",
    "    wf_results = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load single-split backtest results for comparison\n",
    "with open('../outputs/backtest/backtest_results.json', 'r') as f:\n",
    "    bt_results = json.load(f)\n",
    "\n",
    "print(\"Single-split test results:\")\n",
    "for name, result in bt_results.items():\n",
    "    sharpe = result['metrics']['sharpe_ratio']\n",
    "    ret = result['metrics']['total_return'] * 100\n",
    "    print(f\"  {name}: Sharpe={sharpe:.3f}, Return={ret:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-6",
   "metadata": {},
   "source": [
    "## 2. Train/Test Performance Gap Analysis\n",
    "\n",
    "Key question: Is the model overfitting to training data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze feature distributions in train vs test\n",
    "train_data = splits.train\n",
    "test_data = splits.test\n",
    "\n",
    "print(\"Feature distribution comparison (Train vs Test):\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "distribution_stats = []\n",
    "for col in feature_cols:\n",
    "    train_mean = train_data[col].mean()\n",
    "    train_std = train_data[col].std()\n",
    "    test_mean = test_data[col].mean()\n",
    "    test_std = test_data[col].std()\n",
    "    \n",
    "    # Compute distribution shift\n",
    "    mean_shift = (test_mean - train_mean) / train_std if train_std > 0 else 0\n",
    "    \n",
    "    distribution_stats.append({\n",
    "        'Feature': col,\n",
    "        'Train Mean': train_mean,\n",
    "        'Train Std': train_std,\n",
    "        'Test Mean': test_mean,\n",
    "        'Test Std': test_std,\n",
    "        'Mean Shift (std)': mean_shift\n",
    "    })\n",
    "\n",
    "dist_df = pd.DataFrame(distribution_stats)\n",
    "dist_df = dist_df.sort_values('Mean Shift (std)', key=abs, ascending=False)\n",
    "print(dist_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize distribution shifts\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, col in enumerate(feature_cols[:6]):\n",
    "    ax = axes[i]\n",
    "    ax.hist(train_data[col], bins=50, alpha=0.5, label='Train', density=True)\n",
    "    ax.hist(test_data[col], bins=50, alpha=0.5, label='Test', density=True)\n",
    "    ax.set_title(col)\n",
    "    ax.legend()\n",
    "\n",
    "plt.suptitle('Feature Distribution: Train vs Test', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.savefig('../outputs/backtest/feature_distributions.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-9",
   "metadata": {},
   "source": [
    "## 3. Time Period Analysis\n",
    "\n",
    "When does the model fail? Yearly, quarterly, specific periods?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze single-split results by time period\n",
    "best_model = 'qcml_real_only'\n",
    "returns = np.array(bt_results[best_model]['returns'])\n",
    "dates = pd.to_datetime(bt_results[best_model]['dates'])\n",
    "\n",
    "yearly, quarterly, worst = analyze_time_periods(returns, list(dates), n_worst=10)\n",
    "\n",
    "print(\"Yearly Returns:\")\n",
    "print(yearly.to_string())\n",
    "print(\"\\nQuarterly Returns:\")\n",
    "print(quarterly.tail(8).to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize yearly performance\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Yearly returns bar chart\n",
    "colors = ['green' if x > 0 else 'red' for x in yearly.values]\n",
    "axes[0].bar(yearly.index.astype(str), yearly.values * 100, color=colors)\n",
    "axes[0].axhline(y=0, color='black', linestyle='-', linewidth=0.5)\n",
    "axes[0].set_xlabel('Year')\n",
    "axes[0].set_ylabel('Return (%)')\n",
    "axes[0].set_title(f'Yearly Returns: {best_model}')\n",
    "\n",
    "# Quarterly returns\n",
    "q_colors = ['green' if x > 0 else 'red' for x in quarterly.values]\n",
    "axes[1].bar(range(len(quarterly)), quarterly.values * 100, color=q_colors)\n",
    "axes[1].axhline(y=0, color='black', linestyle='-', linewidth=0.5)\n",
    "axes[1].set_xlabel('Quarter')\n",
    "axes[1].set_ylabel('Return (%)')\n",
    "axes[1].set_title(f'Quarterly Returns: {best_model}')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../outputs/backtest/time_period_returns.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Worst periods analysis\n",
    "print(\"\\nWorst 10 Periods (4-week rolling):\")\n",
    "print(worst.to_string())\n",
    "\n",
    "# What was happening in the market during these periods?\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Market Context During Worst Periods\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "spy_returns = prices['SPY'].pct_change()\n",
    "for date in worst.index[:5]:\n",
    "    if date in spy_returns.index:\n",
    "        spy_ret = spy_returns.loc[date]\n",
    "        model_ret = worst.loc[date, 'weekly_return']\n",
    "        print(f\"{date.date()}: Model={model_ret*100:.2f}%, SPY={spy_ret*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-13",
   "metadata": {},
   "source": [
    "## 4. Prediction Quality Analysis\n",
    "\n",
    "How good are the model's predictions at ranking ETFs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load predictions from backtest\n",
    "# Note: We need the raw predictions - these might not be saved\n",
    "# Let's reconstruct from model outputs\n",
    "\n",
    "# Load model and make predictions on test set\n",
    "from qcml_rotation.data.dataset import ETFDataset\n",
    "import torch\n",
    "\n",
    "test_dataset = ETFDataset(splits.test, feature_cols)\n",
    "X_test = test_dataset.features.numpy()\n",
    "y_test = test_dataset.labels.numpy()\n",
    "\n",
    "print(f\"Test set shape: X={X_test.shape}, y={y_test.shape}\")\n",
    "print(f\"Number of tickers: {len(test_dataset.tickers)}\")\n",
    "print(f\"Tickers: {test_dataset.tickers}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load trained model\n",
    "with open('../outputs/qcml/qcml_models.pkl', 'rb') as f:\n",
    "    qcml_models = pickle.load(f)\n",
    "\n",
    "model = qcml_models['qcml_real_only']\n",
    "model.eval()\n",
    "\n",
    "# Make predictions\n",
    "with torch.no_grad():\n",
    "    X_tensor = torch.FloatTensor(X_test)\n",
    "    predictions = model(X_tensor).numpy()\n",
    "\n",
    "print(f\"Predictions shape: {predictions.shape}\")\n",
    "print(f\"Prediction range: [{predictions.min():.4f}, {predictions.max():.4f}]\")\n",
    "print(f\"Prediction std: {predictions.std():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape predictions and actuals to (n_weeks, n_etfs)\n",
    "n_tickers = len(test_dataset.tickers)\n",
    "n_weeks = len(predictions) // n_tickers\n",
    "\n",
    "# Get unique dates and reshape\n",
    "test_dates_unique = splits.test.index.get_level_values('date').unique().sort_values()\n",
    "n_weeks_actual = len(test_dates_unique)\n",
    "\n",
    "print(f\"Samples: {len(predictions)}, Tickers: {n_tickers}, Weeks: {n_weeks_actual}\")\n",
    "\n",
    "# Reshape to (weeks, tickers)\n",
    "predictions_2d = predictions.reshape(n_weeks_actual, n_tickers)\n",
    "actuals_2d = y_test.reshape(n_weeks_actual, n_tickers)\n",
    "\n",
    "print(f\"Reshaped: predictions={predictions_2d.shape}, actuals={actuals_2d.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze prediction quality\n",
    "pred_quality = analyze_prediction_quality(predictions_2d, actuals_2d, top_k=3)\n",
    "\n",
    "print(\"Prediction Quality Metrics:\")\n",
    "print(\"=\"*60)\n",
    "for key, value in pred_quality.items():\n",
    "    if isinstance(value, float):\n",
    "        print(f\"{key}: {value:.4f}\")\n",
    "    else:\n",
    "        print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute weekly rank correlations\n",
    "weekly_correlations = []\n",
    "for week in range(n_weeks_actual):\n",
    "    pred_week = predictions_2d[week]\n",
    "    actual_week = actuals_2d[week]\n",
    "    \n",
    "    if np.std(pred_week) > 0 and np.std(actual_week) > 0:\n",
    "        corr, _ = stats.spearmanr(pred_week, actual_week)\n",
    "        if np.isfinite(corr):\n",
    "            weekly_correlations.append(corr)\n",
    "        else:\n",
    "            weekly_correlations.append(0)\n",
    "    else:\n",
    "        weekly_correlations.append(0)\n",
    "\n",
    "weekly_correlations = np.array(weekly_correlations)\n",
    "\n",
    "print(f\"Weekly Rank Correlations:\")\n",
    "print(f\"  Mean: {weekly_correlations.mean():.4f}\")\n",
    "print(f\"  Std: {weekly_correlations.std():.4f}\")\n",
    "print(f\"  Min: {weekly_correlations.min():.4f}\")\n",
    "print(f\"  Max: {weekly_correlations.max():.4f}\")\n",
    "print(f\"  % Positive: {(weekly_correlations > 0).mean()*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize rank correlation over time\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Weekly correlation time series\n",
    "ax = axes[0, 0]\n",
    "ax.plot(test_dates_unique, weekly_correlations, alpha=0.7)\n",
    "ax.axhline(y=0, color='red', linestyle='--', linewidth=1)\n",
    "ax.axhline(y=weekly_correlations.mean(), color='green', linestyle='--', \n",
    "           label=f'Mean: {weekly_correlations.mean():.3f}')\n",
    "ax.fill_between(test_dates_unique, 0, weekly_correlations, \n",
    "                where=weekly_correlations > 0, alpha=0.3, color='green')\n",
    "ax.fill_between(test_dates_unique, 0, weekly_correlations, \n",
    "                where=weekly_correlations <= 0, alpha=0.3, color='red')\n",
    "ax.set_xlabel('Date')\n",
    "ax.set_ylabel('Spearman Rank Correlation')\n",
    "ax.set_title('Weekly Prediction Rank Correlation')\n",
    "ax.legend()\n",
    "\n",
    "# Histogram of correlations\n",
    "ax = axes[0, 1]\n",
    "ax.hist(weekly_correlations, bins=30, edgecolor='black', alpha=0.7)\n",
    "ax.axvline(x=0, color='red', linestyle='--', linewidth=2)\n",
    "ax.axvline(x=weekly_correlations.mean(), color='green', linestyle='--', linewidth=2)\n",
    "ax.set_xlabel('Rank Correlation')\n",
    "ax.set_ylabel('Frequency')\n",
    "ax.set_title('Distribution of Weekly Rank Correlations')\n",
    "\n",
    "# Rolling average correlation\n",
    "ax = axes[1, 0]\n",
    "rolling_corr = pd.Series(weekly_correlations, index=test_dates_unique).rolling(12).mean()\n",
    "ax.plot(test_dates_unique, rolling_corr, color='blue', linewidth=2)\n",
    "ax.axhline(y=0, color='red', linestyle='--')\n",
    "ax.set_xlabel('Date')\n",
    "ax.set_ylabel('12-Week Rolling Avg Correlation')\n",
    "ax.set_title('Rolling Average Rank Correlation')\n",
    "\n",
    "# Prediction vs Actual scatter (flattened)\n",
    "ax = axes[1, 1]\n",
    "ax.scatter(predictions_2d.flatten(), actuals_2d.flatten(), alpha=0.1, s=5)\n",
    "ax.axhline(y=0, color='gray', linestyle='--', alpha=0.5)\n",
    "ax.axvline(x=0, color='gray', linestyle='--', alpha=0.5)\n",
    "# Add regression line\n",
    "z = np.polyfit(predictions_2d.flatten(), actuals_2d.flatten(), 1)\n",
    "p = np.poly1d(z)\n",
    "x_line = np.linspace(predictions_2d.min(), predictions_2d.max(), 100)\n",
    "ax.plot(x_line, p(x_line), 'r-', linewidth=2, label=f'Fit: y={z[0]:.3f}x+{z[1]:.3f}')\n",
    "ax.set_xlabel('Predicted Return')\n",
    "ax.set_ylabel('Actual Return')\n",
    "ax.set_title('Prediction vs Actual Returns')\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../outputs/backtest/prediction_quality.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-20",
   "metadata": {},
   "source": [
    "## 5. Regime Analysis\n",
    "\n",
    "Does the model perform differently in different market regimes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute SPY returns for regime classification\n",
    "spy_returns = prices['SPY'].pct_change().dropna()\n",
    "\n",
    "# Align with test dates\n",
    "test_dates_list = list(test_dates_unique)\n",
    "spy_test_returns = spy_returns.loc[spy_returns.index.isin(test_dates_list)].values\n",
    "\n",
    "# Analyze regime performance\n",
    "regime_stats = analyze_regime_performance(\n",
    "    returns, \n",
    "    list(dates),\n",
    "    spy_returns=spy_test_returns[:len(returns)] if len(spy_test_returns) >= len(returns) else None\n",
    ")\n",
    "\n",
    "print(\"Performance by Regime:\")\n",
    "print(regime_stats.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize regime performance\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# By volatility regime\n",
    "vol_regime = regime_stats[regime_stats['regime_type'] == 'vol_regime']\n",
    "if len(vol_regime) > 0:\n",
    "    ax = axes[0]\n",
    "    colors = ['green' if x > 0 else 'red' for x in vol_regime['mean_return']]\n",
    "    bars = ax.bar(vol_regime['regime_value'], vol_regime['mean_return'] * 100, color=colors)\n",
    "    ax.axhline(y=0, color='black', linestyle='-', linewidth=0.5)\n",
    "    ax.set_xlabel('Volatility Regime')\n",
    "    ax.set_ylabel('Mean Return (%)')\n",
    "    ax.set_title('Performance by Volatility Regime')\n",
    "    \n",
    "    # Add week counts\n",
    "    for bar, weeks in zip(bars, vol_regime['n_weeks']):\n",
    "        ax.text(bar.get_x() + bar.get_width()/2, bar.get_height(),\n",
    "                f'n={weeks}', ha='center', va='bottom')\n",
    "\n",
    "# By market regime (if available)\n",
    "market_regime = regime_stats[regime_stats['regime_type'] == 'market_regime']\n",
    "if len(market_regime) > 0:\n",
    "    ax = axes[1]\n",
    "    colors = ['green' if x > 0 else 'red' for x in market_regime['mean_return']]\n",
    "    bars = ax.bar(market_regime['regime_value'], market_regime['mean_return'] * 100, color=colors)\n",
    "    ax.axhline(y=0, color='black', linestyle='-', linewidth=0.5)\n",
    "    ax.set_xlabel('Market Regime')\n",
    "    ax.set_ylabel('Mean Return (%)')\n",
    "    ax.set_title('Performance by Market Regime')\n",
    "    \n",
    "    for bar, weeks in zip(bars, market_regime['n_weeks']):\n",
    "        ax.text(bar.get_x() + bar.get_width()/2, bar.get_height(),\n",
    "                f'n={weeks}', ha='center', va='bottom')\n",
    "else:\n",
    "    axes[1].text(0.5, 0.5, 'Market regime data not available', \n",
    "                 ha='center', va='center', transform=axes[1].transAxes)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../outputs/backtest/regime_performance.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-23",
   "metadata": {},
   "source": [
    "## 6. Rolling Performance Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute rolling metrics\n",
    "rolling = compute_rolling_metrics(returns, list(dates), window=26)\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Rolling Sharpe\n",
    "ax = axes[0, 0]\n",
    "ax.plot(rolling.index, rolling['rolling_sharpe'], color='blue')\n",
    "ax.axhline(y=0, color='red', linestyle='--')\n",
    "ax.axhline(y=1, color='green', linestyle='--', alpha=0.5)\n",
    "ax.axhline(y=-1, color='red', linestyle='--', alpha=0.5)\n",
    "ax.fill_between(rolling.index, 0, rolling['rolling_sharpe'], \n",
    "                where=rolling['rolling_sharpe'] > 0, alpha=0.3, color='green')\n",
    "ax.fill_between(rolling.index, 0, rolling['rolling_sharpe'], \n",
    "                where=rolling['rolling_sharpe'] <= 0, alpha=0.3, color='red')\n",
    "ax.set_xlabel('Date')\n",
    "ax.set_ylabel('Sharpe Ratio')\n",
    "ax.set_title('26-Week Rolling Sharpe Ratio')\n",
    "\n",
    "# Rolling Return\n",
    "ax = axes[0, 1]\n",
    "ax.plot(rolling.index, rolling['rolling_return'] * 100, color='blue')\n",
    "ax.axhline(y=0, color='red', linestyle='--')\n",
    "ax.set_xlabel('Date')\n",
    "ax.set_ylabel('Annualized Return (%)')\n",
    "ax.set_title('26-Week Rolling Annualized Return')\n",
    "\n",
    "# Cumulative Return\n",
    "ax = axes[1, 0]\n",
    "ax.plot(rolling.index, (rolling['cumulative'] - 1) * 100, color='blue')\n",
    "ax.axhline(y=0, color='black', linestyle='-', linewidth=0.5)\n",
    "ax.set_xlabel('Date')\n",
    "ax.set_ylabel('Cumulative Return (%)')\n",
    "ax.set_title('Cumulative Return')\n",
    "\n",
    "# Drawdown\n",
    "ax = axes[1, 1]\n",
    "ax.fill_between(rolling.index, rolling['drawdown'] * 100, 0, color='red', alpha=0.5)\n",
    "ax.set_xlabel('Date')\n",
    "ax.set_ylabel('Drawdown (%)')\n",
    "ax.set_title('Drawdown')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../outputs/backtest/rolling_metrics.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-25",
   "metadata": {},
   "source": [
    "## 7. Feature Importance Analysis\n",
    "\n",
    "Which features are most predictive?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple correlation-based feature importance\n",
    "feature_correlations = []\n",
    "\n",
    "for i, col in enumerate(feature_cols):\n",
    "    feature_vals = X_test[:, i]\n",
    "    corr, p_val = stats.pearsonr(feature_vals, y_test)\n",
    "    spearman_corr, sp_p_val = stats.spearmanr(feature_vals, y_test)\n",
    "    \n",
    "    feature_correlations.append({\n",
    "        'Feature': col,\n",
    "        'Pearson Corr': corr,\n",
    "        'Pearson P-val': p_val,\n",
    "        'Spearman Corr': spearman_corr,\n",
    "        'Spearman P-val': sp_p_val,\n",
    "        'Significant': p_val < 0.05\n",
    "    })\n",
    "\n",
    "feat_corr_df = pd.DataFrame(feature_correlations)\n",
    "feat_corr_df = feat_corr_df.sort_values('Pearson Corr', key=abs, ascending=False)\n",
    "print(\"Feature Correlations with Forward Returns:\")\n",
    "print(feat_corr_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize feature correlations\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "colors = ['green' if x else 'gray' for x in feat_corr_df['Significant']]\n",
    "bars = ax.barh(feat_corr_df['Feature'], feat_corr_df['Pearson Corr'], color=colors)\n",
    "ax.axvline(x=0, color='black', linestyle='-', linewidth=0.5)\n",
    "ax.set_xlabel('Pearson Correlation')\n",
    "ax.set_title('Feature Correlation with Forward Returns\\n(Green = Significant at 5%)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../outputs/backtest/feature_importance.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-28",
   "metadata": {},
   "source": [
    "## 8. Statistical Significance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute significance metrics\n",
    "sig = compute_significance(returns, n_bootstrap=1000, random_state=42)\n",
    "\n",
    "print(\"Statistical Significance Analysis:\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Sharpe Ratio: {sig.sharpe_ratio:.4f}\")\n",
    "print(f\"95% CI: [{sig.sharpe_ci_lower:.4f}, {sig.sharpe_ci_upper:.4f}]\")\n",
    "print(f\"P-value (Sharpe > 0): {sig.sharpe_p_value:.4f}\")\n",
    "print(f\"Statistically Significant: {'YES' if sig.is_significant else 'NO'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Permutation test for prediction skill\n",
    "observed_corr, perm_p_val, null_dist = permutation_test(\n",
    "    predictions_2d, actuals_2d, n_permutations=1000, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"\\nPermutation Test for Prediction Skill:\")\n",
    "print(f\"Observed Rank Correlation: {observed_corr:.4f}\")\n",
    "print(f\"P-value: {perm_p_val:.4f}\")\n",
    "print(f\"Prediction Skill Significant: {'YES' if perm_p_val < 0.05 else 'NO'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize permutation test\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "ax.hist(null_dist, bins=50, edgecolor='black', alpha=0.7, label='Null Distribution')\n",
    "ax.axvline(x=observed_corr, color='red', linestyle='--', linewidth=2, \n",
    "           label=f'Observed: {observed_corr:.4f}')\n",
    "ax.axvline(x=np.percentile(null_dist, 95), color='orange', linestyle=':', \n",
    "           label='95th Percentile')\n",
    "ax.set_xlabel('Average Rank Correlation')\n",
    "ax.set_ylabel('Frequency')\n",
    "ax.set_title(f'Permutation Test (p={perm_p_val:.4f})')\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../outputs/backtest/permutation_test.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-32",
   "metadata": {},
   "source": [
    "## 9. Key Findings & Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-33",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"DIAGNOSTIC SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\n1. PREDICTION QUALITY:\")\n",
    "print(f\"   - Average rank correlation: {weekly_correlations.mean():.4f}\")\n",
    "print(f\"   - % weeks with positive correlation: {(weekly_correlations > 0).mean()*100:.1f}%\")\n",
    "print(f\"   - Hit rate (top-3 picks > 0): {pred_quality['hit_rate_top_k']*100:.1f}%\")\n",
    "\n",
    "print(\"\\n2. STATISTICAL SIGNIFICANCE:\")\n",
    "print(f\"   - Sharpe 95% CI: [{sig.sharpe_ci_lower:.3f}, {sig.sharpe_ci_upper:.3f}]\")\n",
    "print(f\"   - P-value (Sharpe > 0): {sig.sharpe_p_value:.4f}\")\n",
    "print(f\"   - Permutation p-value: {perm_p_val:.4f}\")\n",
    "\n",
    "print(\"\\n3. FEATURE ANALYSIS:\")\n",
    "n_significant = feat_corr_df['Significant'].sum()\n",
    "print(f\"   - Features with significant correlation: {n_significant}/{len(feature_cols)}\")\n",
    "if n_significant > 0:\n",
    "    top_feat = feat_corr_df.iloc[0]\n",
    "    print(f\"   - Strongest feature: {top_feat['Feature']} (r={top_feat['Pearson Corr']:.4f})\")\n",
    "\n",
    "print(\"\\n4. REGIME ANALYSIS:\")\n",
    "for _, row in regime_stats.iterrows():\n",
    "    print(f\"   - {row['regime_value']}: mean={row['mean_return']*100:.2f}%, n={row['n_weeks']} weeks\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"RECOMMENDATIONS FOR FEATURE ENGINEERING\")\n",
    "print(\"=\"*70)\n",
    "print(\"\"\"\n",
    "Based on this analysis, the model struggles because:\n",
    "\n",
    "1. LOW PREDICTION SKILL\n",
    "   - Rank correlations are near zero or negative\n",
    "   - Current features lack predictive power for relative ETF performance\n",
    "   \n",
    "2. FEATURE RECOMMENDATIONS\n",
    "   a) Technical Indicators:\n",
    "      - Momentum (20d, 60d returns)\n",
    "      - RSI (Relative Strength Index)\n",
    "      - Bollinger Band %B (mean reversion signal)\n",
    "      - ATR (Average True Range) for volatility\n",
    "   \n",
    "   b) Cross-Sectional Features:\n",
    "      - Rank momentum (relative to other ETFs)\n",
    "      - Sector relative strength\n",
    "      - Z-score of returns\n",
    "   \n",
    "   c) Regime Indicators:\n",
    "      - VIX level and changes\n",
    "      - Yield curve slope\n",
    "      - Credit spreads\n",
    "   \n",
    "   d) Fundamental Flows:\n",
    "      - ETF fund flows (if available)\n",
    "      - Short interest\n",
    "      \n",
    "3. NEXT STEPS\n",
    "   - Implement technical indicator features\n",
    "   - Add cross-sectional rank features\n",
    "   - Test with walk-forward validation\n",
    "   - If still no signal, consider alternative prediction targets\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-34",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nDiagnostic analysis complete!\")\n",
    "print(\"Figures saved to ../outputs/backtest/\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
