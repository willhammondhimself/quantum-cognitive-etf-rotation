{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis\n",
    "\n",
    "Analyze the processed features and labels:\n",
    "- Feature distributions\n",
    "- Correlation matrix\n",
    "- Return distributions by ticker\n",
    "- Temporal patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/processed/processed_data.pkl', 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "splits = data['splits']\n",
    "feature_cols = data['feature_cols']\n",
    "prices = data['prices']\n",
    "config = data['config']\n",
    "\n",
    "# Combine all splits for overview\n",
    "all_data = pd.concat([splits.train, splits.val, splits.test])\n",
    "\n",
    "print(f\"Total samples: {len(all_data)}\")\n",
    "print(f\"Features: {feature_cols}\")\n",
    "print(f\"Tickers: {config['tickers']['etfs']}\")\n",
    "print(f\"Date range: {all_data['date'].min()} to {all_data['date'].max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Feature Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 3, figsize=(15, 8))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, col in enumerate(feature_cols):\n",
    "    ax = axes[idx]\n",
    "    ax.hist(all_data[col], bins=50, alpha=0.7, edgecolor='black')\n",
    "    ax.axvline(x=all_data[col].mean(), color='red', linestyle='--', label=f'Mean: {all_data[col].mean():.4f}')\n",
    "    ax.set_xlabel(col)\n",
    "    ax.set_ylabel('Frequency')\n",
    "    ax.set_title(f'{col}\\nStd: {all_data[col].std():.4f}')\n",
    "    ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../outputs/backtest/feature_distributions.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Feature Correlation Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation matrix including target\n",
    "corr_cols = feature_cols + ['excess_return']\n",
    "corr_matrix = all_data[corr_cols].corr()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "sns.heatmap(corr_matrix, annot=True, fmt='.2f', cmap='RdBu_r', center=0,\n",
    "            square=True, linewidths=0.5, ax=ax)\n",
    "ax.set_title('Feature Correlation Matrix (including target)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../outputs/backtest/correlation_matrix.png', dpi=150)\n",
    "plt.show()\n",
    "\n",
    "# Print correlation with target\n",
    "print(\"\\nCorrelation with excess_return:\")\n",
    "print(corr_matrix['excess_return'].sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Return Distributions by Ticker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Box plot of excess returns by ticker\n",
    "fig, ax = plt.subplots(figsize=(14, 6))\n",
    "\n",
    "# Order by median return\n",
    "ticker_medians = all_data.groupby('ticker')['excess_return'].median().sort_values()\n",
    "order = ticker_medians.index.tolist()\n",
    "\n",
    "sns.boxplot(data=all_data, x='ticker', y='excess_return', order=order, ax=ax)\n",
    "ax.axhline(y=0, color='red', linestyle='--', alpha=0.5)\n",
    "ax.set_xlabel('Ticker')\n",
    "ax.set_ylabel('Excess Return vs SPY')\n",
    "ax.set_title('Distribution of Weekly Excess Returns by Ticker')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../outputs/backtest/returns_by_ticker.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Feature Statistics by Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare feature distributions across splits\n",
    "splits_summary = []\n",
    "\n",
    "for split_name, split_data in [('Train', splits.train), ('Val', splits.val), ('Test', splits.test)]:\n",
    "    row = {'Split': split_name, 'N': len(split_data)}\n",
    "    for col in feature_cols + ['excess_return']:\n",
    "        row[f'{col}_mean'] = split_data[col].mean()\n",
    "        row[f'{col}_std'] = split_data[col].std()\n",
    "    splits_summary.append(row)\n",
    "\n",
    "splits_df = pd.DataFrame(splits_summary).set_index('Split')\n",
    "\n",
    "# Display means\n",
    "mean_cols = [c for c in splits_df.columns if '_mean' in c]\n",
    "print(\"Feature Means by Split:\")\n",
    "display(splits_df[['N'] + mean_cols].round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Temporal Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rolling average of excess returns over time\n",
    "fig, axes = plt.subplots(2, 1, figsize=(14, 8))\n",
    "\n",
    "# Group by date\n",
    "daily_stats = all_data.groupby('date').agg({\n",
    "    'excess_return': ['mean', 'std']\n",
    "}).droplevel(0, axis=1)\n",
    "\n",
    "# Plot mean excess return\n",
    "ax1 = axes[0]\n",
    "ax1.plot(daily_stats.index, daily_stats['mean'] * 100, alpha=0.5, label='Weekly mean')\n",
    "rolling_mean = daily_stats['mean'].rolling(20).mean() * 100\n",
    "ax1.plot(daily_stats.index, rolling_mean, color='red', linewidth=2, label='20-week MA')\n",
    "ax1.axhline(y=0, color='gray', linestyle='--', alpha=0.5)\n",
    "\n",
    "# Mark split boundaries\n",
    "train_end = splits.train['date'].max()\n",
    "val_end = splits.val['date'].max()\n",
    "ax1.axvline(x=train_end, color='green', linestyle='--', alpha=0.7, label='Train/Val split')\n",
    "ax1.axvline(x=val_end, color='blue', linestyle='--', alpha=0.7, label='Val/Test split')\n",
    "\n",
    "ax1.set_xlabel('Date')\n",
    "ax1.set_ylabel('Mean Excess Return (%)')\n",
    "ax1.set_title('Cross-Sectional Mean Excess Return Over Time')\n",
    "ax1.legend(loc='upper left')\n",
    "\n",
    "# Plot volatility\n",
    "ax2 = axes[1]\n",
    "ax2.plot(daily_stats.index, daily_stats['std'] * 100, alpha=0.5, label='Weekly std')\n",
    "rolling_std = daily_stats['std'].rolling(20).mean() * 100\n",
    "ax2.plot(daily_stats.index, rolling_std, color='red', linewidth=2, label='20-week MA')\n",
    "ax2.axvline(x=train_end, color='green', linestyle='--', alpha=0.7)\n",
    "ax2.axvline(x=val_end, color='blue', linestyle='--', alpha=0.7)\n",
    "\n",
    "ax2.set_xlabel('Date')\n",
    "ax2.set_ylabel('Std of Excess Return (%)')\n",
    "ax2.set_title('Cross-Sectional Return Dispersion Over Time')\n",
    "ax2.legend(loc='upper left')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../outputs/backtest/temporal_analysis.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Price Performance Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalized price performance\n",
    "fig, ax = plt.subplots(figsize=(14, 8))\n",
    "\n",
    "# Normalize all prices to start at 1\n",
    "normalized = prices / prices.iloc[0]\n",
    "\n",
    "# Plot SPY prominently\n",
    "ax.plot(normalized.index, normalized['SPY'], color='black', linewidth=2, label='SPY', zorder=10)\n",
    "\n",
    "# Plot others with transparency\n",
    "for ticker in normalized.columns:\n",
    "    if ticker != 'SPY':\n",
    "        ax.plot(normalized.index, normalized[ticker], alpha=0.4, linewidth=1)\n",
    "\n",
    "ax.axhline(y=1, color='gray', linestyle='--', alpha=0.5)\n",
    "ax.set_xlabel('Date')\n",
    "ax.set_ylabel('Normalized Price (start = 1)')\n",
    "ax.set_title('ETF Price Performance (2012-2025)')\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../outputs/backtest/price_performance.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive summary\n",
    "print(\"=\"*60)\n",
    "print(\"DATA SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"\\nDate Range: {all_data['date'].min()} to {all_data['date'].max()}\")\n",
    "print(f\"Total Samples: {len(all_data):,}\")\n",
    "print(f\"Unique Weeks: {all_data['date'].nunique()}\")\n",
    "print(f\"Tickers: {all_data['ticker'].nunique()} ETFs\")\n",
    "\n",
    "print(f\"\\nSplit Sizes:\")\n",
    "print(f\"  Train: {len(splits.train):,} ({len(splits.train)/len(all_data)*100:.1f}%)\")\n",
    "print(f\"  Val:   {len(splits.val):,} ({len(splits.val)/len(all_data)*100:.1f}%)\")\n",
    "print(f\"  Test:  {len(splits.test):,} ({len(splits.test)/len(all_data)*100:.1f}%)\")\n",
    "\n",
    "print(f\"\\nTarget (excess_return) Statistics:\")\n",
    "print(f\"  Mean: {all_data['excess_return'].mean()*100:.4f}%\")\n",
    "print(f\"  Std:  {all_data['excess_return'].std()*100:.4f}%\")\n",
    "print(f\"  Min:  {all_data['excess_return'].min()*100:.4f}%\")\n",
    "print(f\"  Max:  {all_data['excess_return'].max()*100:.4f}%\")\n",
    "\n",
    "print(f\"\\nFeature Descriptions:\")\n",
    "for col in feature_cols:\n",
    "    print(f\"  {col}: mean={all_data[col].mean():.4f}, std={all_data[col].std():.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
