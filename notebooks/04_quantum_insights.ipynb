{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quantum-Cognitive Model Insights\n",
    "\n",
    "Deep dive into QCML model internals:\n",
    "- Hilbert space embeddings visualization\n",
    "- Hermitian observable analysis\n",
    "- Ablation comparison\n",
    "- Complex vs real embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "import torch\n",
    "\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Models and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "with open('../data/processed/processed_data.pkl', 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "# Load QCML models\n",
    "with open('../outputs/qcml/qcml_models.pkl', 'rb') as f:\n",
    "    qcml_models = pickle.load(f)\n",
    "\n",
    "splits = data['splits']\n",
    "feature_cols = data['feature_cols']\n",
    "\n",
    "# Get test data\n",
    "X_test = splits.test[feature_cols].values\n",
    "y_test = splits.test['excess_return'].values\n",
    "tickers_test = splits.test['ticker'].values\n",
    "\n",
    "device = torch.device('mps' if torch.backends.mps.is_available() else 'cpu')\n",
    "\n",
    "print(f\"Models loaded: {list(qcml_models.keys())}\")\n",
    "print(f\"Test samples: {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Extract Hilbert Space Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_embeddings(model, X):\n",
    "    \"\"\"Extract Hilbert space state vectors from QCML model.\"\"\"\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        X_tensor = torch.FloatTensor(X).to(device)\n",
    "        \n",
    "        # Get state vectors from encoder\n",
    "        psi = model.encoder(X_tensor)  # Shape: (batch, hilbert_dim) or (batch, 2*hilbert_dim)\n",
    "        \n",
    "    return psi.cpu().numpy()\n",
    "\n",
    "# Extract embeddings from each model\n",
    "embeddings = {}\n",
    "for name, model in qcml_models.items():\n",
    "    embeddings[name] = extract_embeddings(model, X_test)\n",
    "    print(f\"{name}: embedding shape = {embeddings[name].shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Visualize Embeddings with t-SNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t-SNE visualization of embeddings colored by actual return\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "for idx, (name, emb) in enumerate(embeddings.items()):\n",
    "    ax = axes[idx]\n",
    "    \n",
    "    # Run t-SNE (use real part if complex)\n",
    "    emb_real = np.real(emb) if np.iscomplexobj(emb) else emb\n",
    "    \n",
    "    # Subsample for speed\n",
    "    n_samples = min(1000, len(emb_real))\n",
    "    idx_sample = np.random.choice(len(emb_real), n_samples, replace=False)\n",
    "    \n",
    "    tsne = TSNE(n_components=2, random_state=42, perplexity=30)\n",
    "    emb_2d = tsne.fit_transform(emb_real[idx_sample])\n",
    "    \n",
    "    # Color by actual return\n",
    "    colors = y_test[idx_sample] * 100\n",
    "    scatter = ax.scatter(emb_2d[:, 0], emb_2d[:, 1], c=colors, cmap='RdYlGn', \n",
    "                         alpha=0.6, s=20, vmin=-5, vmax=5)\n",
    "    \n",
    "    ax.set_xlabel('t-SNE 1')\n",
    "    ax.set_ylabel('t-SNE 2')\n",
    "    ax.set_title(f'{name}\\nHilbert Space Embeddings')\n",
    "    plt.colorbar(scatter, ax=ax, label='Excess Return (%)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../outputs/backtest/hilbert_embeddings_tsne.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Analyze Hermitian Observable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract and analyze the Hermitian observable from qcml_full\n",
    "model = qcml_models['qcml_full']\n",
    "\n",
    "# Get observable weights\n",
    "W_real = model.observable.W_real.detach().cpu().numpy()\n",
    "W_imag = model.observable.W_imag.detach().cpu().numpy() if hasattr(model.observable, 'W_imag') else None\n",
    "\n",
    "print(f\"Observable W_real shape: {W_real.shape}\")\n",
    "\n",
    "# Reconstruct Hermitian matrix: W = A + A†\n",
    "if W_imag is not None:\n",
    "    A = W_real + 1j * W_imag\n",
    "    W = A + A.conj().T\n",
    "else:\n",
    "    W = W_real + W_real.T\n",
    "\n",
    "# Eigenvalue analysis\n",
    "eigenvalues, eigenvectors = np.linalg.eigh(np.real(W))\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "# Eigenvalue spectrum\n",
    "axes[0].bar(range(len(eigenvalues)), eigenvalues)\n",
    "axes[0].set_xlabel('Eigenvalue Index')\n",
    "axes[0].set_ylabel('Eigenvalue')\n",
    "axes[0].set_title('Hermitian Observable Eigenspectrum')\n",
    "\n",
    "# Observable matrix heatmap (real part)\n",
    "im1 = axes[1].imshow(np.real(W), cmap='RdBu_r', aspect='auto')\n",
    "axes[1].set_title('Observable Matrix (Real Part)')\n",
    "axes[1].set_xlabel('Hilbert Dim')\n",
    "axes[1].set_ylabel('Hilbert Dim')\n",
    "plt.colorbar(im1, ax=axes[1])\n",
    "\n",
    "# Observable matrix (imaginary part if exists)\n",
    "if W_imag is not None:\n",
    "    im2 = axes[2].imshow(np.imag(W), cmap='RdBu_r', aspect='auto')\n",
    "    axes[2].set_title('Observable Matrix (Imaginary Part)')\n",
    "else:\n",
    "    axes[2].text(0.5, 0.5, 'No Imaginary Part\\n(Real-only model)', ha='center', va='center', fontsize=12)\n",
    "    axes[2].set_title('Observable Matrix (Imaginary Part)')\n",
    "axes[2].set_xlabel('Hilbert Dim')\n",
    "axes[2].set_ylabel('Hilbert Dim')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../outputs/backtest/hermitian_observable.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Ablation Comparison: Complex vs Real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare predictions from complex vs real-only models\n",
    "predictions = {}\n",
    "for name, model in qcml_models.items():\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        X_tensor = torch.FloatTensor(X_test).to(device)\n",
    "        predictions[name] = model(X_tensor).cpu().numpy().flatten()\n",
    "\n",
    "# Scatter: full vs real-only predictions\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Full vs Real-only\n",
    "ax = axes[0]\n",
    "ax.scatter(predictions['qcml_full'] * 100, predictions['qcml_real_only'] * 100, alpha=0.3, s=10)\n",
    "ax.plot([-2, 2], [-2, 2], 'r--', alpha=0.5, label='y=x')\n",
    "ax.set_xlabel('qcml_full predictions (%)')\n",
    "ax.set_ylabel('qcml_real_only predictions (%)')\n",
    "ax.set_title('Complex vs Real-Only Predictions')\n",
    "corr = np.corrcoef(predictions['qcml_full'], predictions['qcml_real_only'])[0, 1]\n",
    "ax.text(0.05, 0.95, f'Correlation: {corr:.3f}', transform=ax.transAxes, va='top')\n",
    "ax.legend()\n",
    "\n",
    "# Full vs No-ranking\n",
    "ax = axes[1]\n",
    "ax.scatter(predictions['qcml_full'] * 100, predictions['qcml_no_ranking'] * 100, alpha=0.3, s=10)\n",
    "ax.plot([-2, 2], [-2, 2], 'r--', alpha=0.5, label='y=x')\n",
    "ax.set_xlabel('qcml_full predictions (%)')\n",
    "ax.set_ylabel('qcml_no_ranking predictions (%)')\n",
    "ax.set_title('With Ranking vs Without Ranking')\n",
    "corr = np.corrcoef(predictions['qcml_full'], predictions['qcml_no_ranking'])[0, 1]\n",
    "ax.text(0.05, 0.95, f'Correlation: {corr:.3f}', transform=ax.transAxes, va='top')\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../outputs/backtest/ablation_comparison.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Embedding Norm Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if state vectors are normalized (quantum requirement)\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "for idx, (name, emb) in enumerate(embeddings.items()):\n",
    "    ax = axes[idx]\n",
    "    \n",
    "    # Compute norms\n",
    "    norms = np.linalg.norm(emb, axis=1)\n",
    "    \n",
    "    ax.hist(norms, bins=50, alpha=0.7, edgecolor='black')\n",
    "    ax.axvline(x=1.0, color='red', linestyle='--', label='Unit norm')\n",
    "    ax.axvline(x=norms.mean(), color='green', linestyle='-', label=f'Mean: {norms.mean():.4f}')\n",
    "    \n",
    "    ax.set_xlabel('State Vector Norm')\n",
    "    ax.set_ylabel('Frequency')\n",
    "    ax.set_title(f'{name}\\nNorm Distribution')\n",
    "    ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../outputs/backtest/embedding_norms.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Embeddings by Ticker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t-SNE colored by ticker\n",
    "best_model = 'qcml_real_only'  # Best performing model\n",
    "emb = embeddings[best_model]\n",
    "emb_real = np.real(emb) if np.iscomplexobj(emb) else emb\n",
    "\n",
    "# Subsample\n",
    "n_samples = min(2000, len(emb_real))\n",
    "idx_sample = np.random.choice(len(emb_real), n_samples, replace=False)\n",
    "\n",
    "tsne = TSNE(n_components=2, random_state=42, perplexity=30)\n",
    "emb_2d = tsne.fit_transform(emb_real[idx_sample])\n",
    "\n",
    "# Create ticker mapping\n",
    "unique_tickers = np.unique(tickers_test)\n",
    "ticker_to_id = {t: i for i, t in enumerate(unique_tickers)}\n",
    "ticker_ids = np.array([ticker_to_id[t] for t in tickers_test[idx_sample]])\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 10))\n",
    "scatter = ax.scatter(emb_2d[:, 0], emb_2d[:, 1], c=ticker_ids, cmap='tab20', alpha=0.6, s=20)\n",
    "\n",
    "# Add legend\n",
    "handles = [plt.scatter([], [], c=plt.cm.tab20(i/len(unique_tickers)), label=t) \n",
    "           for i, t in enumerate(unique_tickers)]\n",
    "ax.legend(handles=handles, title='Ticker', loc='center left', bbox_to_anchor=(1, 0.5), ncol=1)\n",
    "\n",
    "ax.set_xlabel('t-SNE 1')\n",
    "ax.set_ylabel('t-SNE 2')\n",
    "ax.set_title(f'{best_model}: Embeddings by Ticker')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../outputs/backtest/embeddings_by_ticker.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Model Architecture Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print model architecture details\n",
    "print(\"=\"*60)\n",
    "print(\"QCML MODEL ARCHITECTURE\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for name, model in qcml_models.items():\n",
    "    print(f\"\\n{name}:\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    # Count parameters\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    \n",
    "    print(f\"  Total parameters: {total_params:,}\")\n",
    "    print(f\"  Trainable parameters: {trainable_params:,}\")\n",
    "    \n",
    "    # Model components\n",
    "    print(f\"  Components:\")\n",
    "    for child_name, child in model.named_children():\n",
    "        child_params = sum(p.numel() for p in child.parameters())\n",
    "        print(f\"    - {child_name}: {child_params:,} params\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Key Quantum Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"KEY QUANTUM INSIGHTS\")\n",
    "print(\"=\"*60)\n",
    "print(\"\"\"\n",
    "1. STATE VECTOR NORMALIZATION:\n",
    "   - All models enforce unit-norm state vectors (|ψ| = 1)\n",
    "   - This ensures proper quantum probability interpretation\n",
    "\n",
    "2. COMPLEX VS REAL EMBEDDINGS:\n",
    "   - Surprisingly, real-only embeddings outperform complex\n",
    "   - Complex phase information may be overfitting to noise\n",
    "   - Simpler models generalize better on this dataset\n",
    "\n",
    "3. HERMITIAN OBSERVABLE:\n",
    "   - Observable eigenspectrum shows learned price patterns\n",
    "   - Largest eigenvalues capture dominant return factors\n",
    "\n",
    "4. RANKING LOSS EFFECT:\n",
    "   - Ranking loss improves prediction correlation\n",
    "   - But doesn't improve trading returns (possible overfitting)\n",
    "   \n",
    "5. TICKER CLUSTERING:\n",
    "   - Similar ETFs cluster in Hilbert space\n",
    "   - Model learns meaningful financial relationships\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
